{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "32aad903fee5d45b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:06:04.370410Z",
     "start_time": "2025-03-30T12:06:03.905700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import NearestNeighbors"
   ],
   "id": "20eecb392657aee6",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Path to CAPTCHA dataset\n",
    "dataset_path = r\"D:\\Downloads\\CAPTCHA\"\n",
    "\n",
    "# Function to preprocess CAPTCHA images\n",
    "def preprocess_captcha(image_path, width=128, height=64):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(f\"⚠️ Skipping file (failed to load): {image_path}\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (width, height))\n",
    "    image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                  cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    return image"
   ],
   "id": "a75234e2b4854388",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:06:29.988028Z",
     "start_time": "2025-03-30T12:06:29.979292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to extract label from filename\n",
    "def get_label_from_filename(filename):\n",
    "    return os.path.splitext(filename)[0]\n",
    "\n",
    "# Function to convert image into a graph\n",
    "def image_to_graph(image_path, num_neighbors=5):\n",
    "    image = preprocess_captcha(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if len(keypoints) == 0:\n",
    "        print(f\"⚠️ Skipping {image_path}: No keypoints found\")\n",
    "        return None\n",
    "    nodes = np.array([kp.pt for kp in keypoints], dtype=np.float32)\n",
    "    nbrs = NearestNeighbors(n_neighbors=num_neighbors, algorithm='ball_tree').fit(nodes)\n",
    "    _, indices = nbrs.kneighbors(nodes)\n",
    "    edge_index = torch.tensor([(i, neighbor) for i, neighbors in enumerate(indices) for neighbor in neighbors if i != neighbor], dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(nodes, dtype=torch.float)\n",
    "    return Data(x=x, edge_index=edge_index)"
   ],
   "id": "f317e01ef25a6fb0",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:20:19.203047Z",
     "start_time": "2025-03-30T12:06:48.719702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "graph_data_list = []\n",
    "labels = []\n",
    "image_files = [f for f in os.listdir(dataset_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "for file in image_files:\n",
    "    graph_data = image_to_graph(os.path.join(dataset_path, file))\n",
    "    if graph_data is not None:\n",
    "        graph_data_list.append(graph_data)\n",
    "        labels.append(get_label_from_filename(file))\n",
    "\n",
    "print(f\"✅ Total valid graphs: {len(graph_data_list)}\")"
   ],
   "id": "3b8b9046bf7a9f13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total valid graphs: 113062\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:20:19.879001Z",
     "start_time": "2025-03-30T12:20:19.245532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode labels\n",
    "char_set = string.ascii_uppercase + string.digits\n",
    "char_to_index = {char: i for i, char in enumerate(char_set)}\n",
    "def encode_label(label):\n",
    "    return [char_to_index[c.upper()] for c in label]\n",
    "encoded_labels = [encode_label(label) for label in labels]"
   ],
   "id": "b75100da10533930",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:20:19.904635Z",
     "start_time": "2025-03-30T12:20:19.885976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom dataset class\n",
    "class CaptchaGraphDataset(Dataset):\n",
    "    def __init__(self, graph_data_list, encoded_labels):\n",
    "        self.graph_data_list = graph_data_list\n",
    "        self.encoded_labels = encoded_labels\n",
    "    def __len__(self):\n",
    "        return len(self.graph_data_list)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graph_data_list[idx], torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "train_size = int(0.8 * len(graph_data_list))\n",
    "test_size = len(graph_data_list) - train_size\n",
    "train_dataset, test_dataset = random_split(CaptchaGraphDataset(graph_data_list, encoded_labels), [train_size, test_size])\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Total Batches: {len(train_loader)}\")"
   ],
   "id": "6aa1e3cf0d96640",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Batches: 5654\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:20:19.927119Z",
     "start_time": "2025-03-30T12:20:19.920714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define GNN Model\n",
    "class CaptchaGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(CaptchaGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.fc(x)\n",
    "        x = x.unsqueeze(1)  # Shape for CTC loss\n",
    "        return x"
   ],
   "id": "eaadbcc57079b8c",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-30T12:20:19.941805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model setup\n",
    "input_dim = 2  # (x, y) coordinates\n",
    "hidden_dim = 64\n",
    "output_dim = len(char_set)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CaptchaGNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "criterion = nn.CTCLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, labels in train_loader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data).log_softmax(2)\n",
    "        labels = labels.view(-1)\n",
    "        input_lengths = torch.tensor([output.size(0)], dtype=torch.long, device=device)\n",
    "        target_lengths = torch.tensor([labels.numel()], dtype=torch.long, device=device)\n",
    "        loss = criterion(output, labels, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"captcha_gnn.pth\")\n",
    "print(\"✅ Model saved as captcha_gnn.pth\")"
   ],
   "id": "94adf90656c201b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 88360.2914\n",
      "Epoch [2/10], Loss: 81529.0842\n",
      "Epoch [3/10], Loss: 77146.0000\n",
      "Epoch [4/10], Loss: 78372.0182\n",
      "Epoch [5/10], Loss: 78151.0572\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate model\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(data).argmax(dim=2)\n",
    "        total_correct += (output == labels).sum().item()\n",
    "        total_samples += labels.numel()\n",
    "accuracy = total_correct / total_samples * 100\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ],
   "id": "7d228dd6cc4768a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Inference on new CAPTCHA image\n",
    "def predict_captcha(image_path):\n",
    "    graph_data = image_to_graph(image_path)\n",
    "    if graph_data is None:\n",
    "        return None\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        graph_data = graph_data.to(device)\n",
    "        output = model(graph_data).argmax(dim=2).cpu().numpy()\n",
    "    predicted_text = ''.join([char_set[i] for i in output.flatten()])\n",
    "    return predicted_text\n",
    "\n",
    "# Example usage\n",
    "sample_image = R\"D:\\Downloads\\Large_Captcha_Dataset\\001up.png\"\n",
    "predicted_text = predict_captcha(sample_image)\n",
    "print(f\"Predicted CAPTCHA Text: {predicted_text}\")\n"
   ],
   "id": "9901348781483a35"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
